[2025-05-12T08:05:58.245+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: news_scraping_pipeline.scrape_news manual__2025-05-12T08:00:22.522379+00:00 [queued]>
[2025-05-12T08:05:58.264+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: news_scraping_pipeline.scrape_news manual__2025-05-12T08:00:22.522379+00:00 [queued]>
[2025-05-12T08:05:58.266+0000] {taskinstance.py:1359} INFO - Starting attempt 2 of 2
[2025-05-12T08:05:58.345+0000] {taskinstance.py:1380} INFO - Executing <Task(DockerOperator): scrape_news> on 2025-05-12 08:00:22.522379+00:00
[2025-05-12T08:05:58.369+0000] {standard_task_runner.py:57} INFO - Started process 52 to run task
[2025-05-12T08:05:58.402+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'news_scraping_pipeline', 'scrape_news', 'manual__2025-05-12T08:00:22.522379+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/news_scraping_dag.py', '--cfg-path', '/tmp/tmpt9j3g3zo']
[2025-05-12T08:05:58.410+0000] {standard_task_runner.py:85} INFO - Job 32: Subtask scrape_news
[2025-05-12T08:05:58.452+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 32 for task scrape_news (invalid interpolation syntax in 'dag_id={{ ti.dag_id }}/run_id={{ ti.run_id }}/task_id={{ ti.task_id }}/{% if ti.map_index >= 0 %}map_index={{ ti.map_index }}/{% endif %}attempt={{ try_number }}.log' at position 72; 52)
[2025-05-12T08:05:58.499+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-05-12T08:05:58.557+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
